# -*- snakemake -*-
# vim: ft=python
# vim: syntax=snakemake

import yaml
import itertools
import pandas
import sys

try:
    config.update(yaml.load(open('config.yaml')))
except IOError:
    raise IOError('No "config.yaml" found; please supply another config '
                  ' file using the --configfile argument')

shell.prefix(config.get('shell_prefix', ''))

# ----------------------------------------------------------------------------
# Helper functions
#
HERE = srcdir('')
WRAPPERS = '../../wrappers'
sys.path.insert(0, os.path.join(HERE, '../../lcdb'))
import helpers
wrapper_for, params_for, threads_for = helpers.workflow_helper_functions(config, HERE, WRAPPERS)

from interface import SampleHandler


def fastq_screen_config_inputs():
    """
    Returns indexes and a table (as string) that can be written directly to
    a config file.

    Use indexes as the input to a rule; use the table to build a config file.
    """
    indexes = config['rules']['fastq_screen']['indexes']
    aligner = config['rules']['fastq_screen']['aligner']
    inputs = []
    for label, prefix in indexes.items():
        prefix = os.path.join(config['data_dir'], prefix)
        inputs.extend(expand(prefix + '.{n}.bt2', n=[1, 2, 3, 4]))
    return inputs


sampletable = helpers.load_sampletable(config['sampletable'])
samples = sampletable.index.tolist()

include: '../references/Snakefile'

# ----------------------------------------------------------------------------
# Aligner configuration.
#
ALIGNER = config['rules']['align']['aligner']
ALIGNER_PREFIX = config['rules']['align']['prefix']
ALIGNER_TAG= {'bowtie2': 'bt2',  'hisat2': 'ht2'}[ALIGNER]

if ALIGNER == 'hisat2':
    ALIGNER_INDEX = expand('{data_dir}/{prefix}.{n}.{tag}',
                           prefix=ALIGNER_PREFIX,
                           n=range(1, 9),
                           tag=ALIGNER_TAG,
                           data_dir = config['data_dir'])

if ALIGNER == 'bowtie2':
    ALIGNER_INDEX = expand('{data_dir}/{prefix}.{n}.{tag}',
                           prefix=ALIGNER_PREFIX,
                           n=range(1, 5),
                           tag=ALIGNER_TAG,
                           data_dir = config['data_dir'])

# ----------------------------------------------------------------------------
# Generate final targets
#
patterns = [
    '{runLevel}.fastq.count',
    '{runLevel}.fastqc.html',
    '{runLevel}.fastq_screen.txt',
    '{runLevel}.fastq_screen.png',
    '{runLevel}.cutadapt.fastqc.html',
    '{runLevel}.cutadapt.fastq.gz',
    '{runLevel}.cutadapt.fastq.count',
    '{runLevel}.cutadapt.{aligner_tag}.bam',
    '{runLevel}.cutadapt.{aligner_tag}.bam.count',
    '{runLevel}.cutadapt.{aligner_tag}.unique.bam.observed_complexity',
    '{runLevel}.cutadapt.{aligner_tag}.unique.bam.estimated_complexity',
    '{runLevel}.cutadapt.{aligner_tag}.unique.bam.estimated_coverage',
    '{runLevel}.cutadapt.{aligner_tag}.unique.sort.dedup.bam',
    '{runLevel}.cutadapt.{aligner_tag}.unique.sort.dedup.bam.count',
    '{runLevel}.cutadapt.{aligner_tag}.unique.sort.dedup.metrics',
    '{aggLevel}.cutadapt.{aligner_tag}.merged.unique.sort.dedup.bam',
    '{aggLevel}.cutadapt.{aligner_tag}.merged.unique.sort.dedup.bam.count',
    'multiqc_report.html',
    'fastq_screen_config.txt',
] + fastq_screen_config_inputs() + ALIGNER_INDEX
# ----------------------------------------------------------------------------


config['aligner_tag'] = ALIGNER_TAG
SH = SampleHandler(config)

targets = SH.build_targets(patterns)
rule all:
    input: targets


rule clean:
    run:
        if os.path.exists(config['sample_dir']):
            shell('rm -r {config[sample_dir]}')
        shell('wget -O - http://helix.nih.gov/~dalerr/lcdb-workflows-data/pasilla.tar > pasilla.tar')
        shell('tar -xvf pasilla.tar')
        shell('rm pasilla.tar')


rule fastqc:
    input: '{prefix}{suffix}.fastq.gz'
    output:
        html='{prefix}{suffix}.fastqc.html',
        zip='{prefix}{suffix}_fastqc.zip',
    params: extra=params_for('fastqc', 'extra')
    wrapper:
        wrapper_for('fastqc')


rule cutadapt:
    input: '{prefix}.fastq.gz'
    output: '{prefix}.cutadapt.fastq.gz'
    log: '{prefix}.cutadapt.fastq.log'
    params: extra=params_for('cutadapt', 'extra')
    wrapper:
        wrapper_for('cutadapt')

rule align:
    input:
        fastq='{prefix}.fastq.gz',
        index=ALIGNER_INDEX
    output: '{prefix}.{tag}.bam'
    log: '{prefix}.{tag}.bam.log'
    params: extra=params_for('align', 'extra')
    threads: threads_for('align')
    wrapper:
        wrapper_for(ALIGNER)


def multiqc_inputs():
    inputs = []
    check_for = ['fastq', 'bam']
    for i in targets:
        for j in check_for:
            if j in i:
                # Doesn't matter which of `check_for` we found, just *that* we
                # found one, so we only add the input once.
                inputs.append(i)
                break
    return inputs


rule multiqc:
    input: multiqc_inputs()
    output: 'multiqc_report.html'
    log: 'multiqc_report.log'
    params: analysis_directory=config['sample_dir']
    wrapper:
        wrapper_for('multiqc')



rule fastq_screen_config_file:
    input: fastq_screen_config_inputs()
    output: 'fastq_screen_config.txt'
    run:
        indexes = config['rules']['fastq_screen']['indexes']
        aligner = config['rules']['fastq_screen']['aligner']
        inputs = []
        table = []
        for label, prefix in indexes.items():
            prefix = os.path.join(config['data_dir'], prefix)
            table.append(['DATABASE', label, prefix, aligner.upper()])

        with open(output[0], 'w') as fout:
            fout.write('\n'.join(['\t'.join(i) for i in sorted(table)]) + '\n')


rule fastq_screen:
    input:
        '{prefix}.fastq.gz',
        'fastq_screen_config.txt'
    output:
        txt='{prefix}.fastq_screen.txt',
        png='{prefix}.fastq_screen.png'
    log: '{prefix}.fastq_screen.log'
    params: fastq_screen_config='fastq_screen_config.txt'
    wrapper:
        wrapper_for('fastq_screen')


rule samtools_unique:
    input: '{prefix}.cutadapt.{aligner_tag}.bam'
    output: '{prefix}.cutadapt.{aligner_tag}.unique.bam'
    params: extra=params_for('samtools_unique', 'extra')
    wrapper:
        wrapper_for('samtools/view')


rule samtools_sort:
    input: '{prefix}.cutadapt.{aligner_tag}.unique.bam'
    output: '{prefix}.cutadapt.{aligner_tag}.unique.sort.bam'
    wrapper:
        wrapper_for('samtools/sort')


rule samtools_index:
    input: '{prefix}.cutadapt.{aligner_tag}.unique.sort.bam'
    output: '{prefix}.cutadapt.{aligner_tag}.unique.sort.bam.bai'
    wrapper:
        wrapper_for('samtools/index')


rule preseq_observed_complexity:
    input: '{prefix}.cutadapt.{aligner_tag}.unique.sort.bam'
    output: '{prefix}.cutadapt.{aligner_tag}.unique.bam.observed_complexity'
    wrapper:
        wrapper_for('preseq/observed_complexity')


rule preseq_expected_complexity:
    input: '{prefix}.cutadapt.{aligner_tag}.unique.sort.bam'
    output: '{prefix}.cutadapt.{aligner_tag}.unique.bam.estimated_complexity'
    wrapper:
        wrapper_for('preseq/estimated_complexity')


rule preseq_expected_coverage:
    input: '{prefix}.cutadapt.{aligner_tag}.unique.sort.bam'
    output: '{prefix}.cutadapt.{aligner_tag}.unique.bam.estimated_coverage'
    wrapper:
        wrapper_for('preseq/estimated_coverage')


rule picard_MarkDuplicates:
    input:
        bam = '{prefix}.cutadapt.{aligner_tag}.unique.sort.bam',
        bai = '{prefix}.cutadapt.{aligner_tag}.unique.sort.bam.bai'
    output:
        bam = '{prefix}.cutadapt.{aligner_tag}.unique.sort.dedup.bam',
        metrics = '{prefix}.cutadapt.{aligner_tag}.unique.sort.dedup.metrics'
    params: extra=params_for('picard_MarkDuplicates', 'extra')
    log: '{prefix}.cutadapt.{aligner_tag}.unique.sort.dedup.log',
    wrapper:
        wrapper_for('picard/MarkDuplicates')

rule merge_bam:
    input: SH.make_input(prefix='prefix', midfix='.cutadapt.{aligner_tag}', suffix='.unique.sort.dedup.bam', agg=True)
    output: '{prefix}.cutadapt.{aligner_tag}.merged.unique.sort.dedup.bam'
    wrapper:
        wrapper_for('samtools/merge')


rule fastq_count:
    input: '{prefix}.fastq.gz'
    output: '{prefix}.fastq.count'
    shell: "gunzip -c {input[0]} | echo $((`wc -l` / 4)) > {output[0]}"


rule bam_count:
    input: '{prefix}.bam'
    output: '{prefix}.bam.count'
    shell: "samtools view -c {input[0]} > {output[0]}"


rule count_table:
    input: 
    output: csv = 'count_table.csv',
            html = 'count_table.html'
    run:
        import pandas as pd
        


rule report:
    input: F1='img.png'
    output: html='report.html'
    run:
        from lcdb.reporting import report
        
        report("""\
        # Mapping Workflow Report

        """,  **input)

